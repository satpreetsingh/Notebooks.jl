{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T19:26:08.041751",
     "start_time": "2016-11-02T11:26:17.536Z"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module RNN\n",
      "WARNING: Method definition writeas(Knet.KnetArray) in module RNN at In[35]:192 overwritten in module RNN at In[38]:193.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module RNN\n",
    "\n",
    "using Knet,AutoGrad,JLD\n",
    "export Knet,JLD\n",
    "\n",
    "o = Dict()\n",
    "o[:loadfile] = nothing\n",
    "o[:bestfile] = \"/tmp/CharLM-best.jld\"\n",
    "o[:hidden] = [256]\n",
    "o[:embed] = 256\n",
    "o[:epochs] = 3\n",
    "o[:batchsize] = 128\n",
    "o[:seqlength] = 50 # 100\n",
    "o[:decay] = 0.9\n",
    "o[:lr] = 1.0\n",
    "o[:gclip] = 3.0\n",
    "o[:winit] = 0.3\n",
    "o[:gcheck] = 0\n",
    "o[:seed] = -1\n",
    "o[:atype] = KnetArray{Float32}\n",
    "o[:fast] = true\n",
    "\n",
    "function initialize(x, y, o)\n",
    "    data = [minibatch(x, y, o[:batchsize])]\n",
    "    initialize(data, o)\n",
    "end\n",
    "\n",
    "function initialize(data, o)\n",
    "    if o[:loadfile]==nothing\n",
    "        model = initweights(o[:atype], o[:hidden], data, o[:embed], o[:winit])\n",
    "    else\n",
    "        info(\"Loading model from $(o[:loadfile])\")\n",
    "        model = map(p->convert(o[:atype],p), load(o[:loadfile], \"model\"))\n",
    "    end\n",
    "    model\n",
    "end\n",
    "\n",
    "function minibatch(x, y, batch_size)\n",
    "    n, dx, dy = size(x,2), size(x,1), size(y,1)\n",
    "    nbatch = div(n, batch_size)\n",
    "    data = [(zeros(batch_size,dx),zeros(batch_size,dy)) for i=1:nbatch ] \n",
    "    cidx = 0\n",
    "    for idx = 1:size(x,2)           # safest way to iterate over utf-8 text\n",
    "        idata = 1 + idx % nbatch\n",
    "        row = 1 + div(idx, nbatch)\n",
    "        row > batch_size && break\n",
    "        data[idata][1][row,:] = x[:,idx]\n",
    "        data[idata][2][row,:] = y[:,idx]\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "function train!(model, data, o)\n",
    "    s0 = initstate(o[:atype], o[:hidden], o[:batchsize])\n",
    "    lr = o[:lr]\n",
    "    if o[:fast]\n",
    "        @time (for epoch=1:o[:epochs]\n",
    "               train1(model, copy(s0), data[1]; slen=o[:seqlength], lr=lr, gclip=o[:gclip])\n",
    "               end; Knet.cudaDeviceSynchronize())\n",
    "        return\n",
    "    end    \n",
    "    losses = map(d->loss(model,copy(s0),d), data)\n",
    "    println((:epoch,0,:loss,losses...))\n",
    "    devset = ifelse(length(data) > 1, 2, 1)\n",
    "    devlast = devbest = losses[devset]\n",
    "    for epoch=1:o[:epochs]\n",
    "        @time train1(model, copy(s0), data[1]; slen=o[:seqlength], lr=lr, gclip=o[:gclip])\n",
    "        @time losses = map(d->loss(model,copy(s0),d), data)\n",
    "        println((:epoch,epoch,:loss,losses...))\n",
    "        if o[:gcheck] > 0\n",
    "            gradcheck(loss, model, copy(s0), data[1], 1:o[:seqlength]; gcheck=o[:gcheck])\n",
    "        end\n",
    "        devloss = losses[devset]\n",
    "        if devloss < devbest\n",
    "            devbest = devloss\n",
    "            if o[:bestfile] != nothing\n",
    "                info(\"Saving best model to $(o[:bestfile])\")\n",
    "                save(o[:bestfile], \"model\", model)\n",
    "            end\n",
    "        end\n",
    "        if devloss > devlast\n",
    "            lr *= o[:decay]\n",
    "            info(\"New learning rate: $lr\")\n",
    "        end\n",
    "        devlast = devloss\n",
    "    end\n",
    "end    \n",
    "\n",
    "\n",
    "# sequence[t]: input token at time t\n",
    "# state is modified in place\n",
    "function train1(param, state, sequence; slen=100, lr=1.0, gclip=0.0)\n",
    "    for t = 1:slen:length(sequence)-slen\n",
    "        range = t:t+slen-1\n",
    "        gloss = lossgradient(param, state, sequence, range)\n",
    "        gscale = lr\n",
    "        if gclip > 0\n",
    "            gnorm = sqrt(mapreduce(sumabs2, +, 0, gloss))\n",
    "            if gnorm > gclip\n",
    "                gscale *= gclip / gnorm\n",
    "            end\n",
    "        end\n",
    "        gnorm = sqrt(mapreduce(sumabs2, +, 0, gloss))\n",
    "        for k in 1:length(param)\n",
    "            # param[k] -= gscale * gloss[k]\n",
    "            Knet.axpy!(-gscale, gloss[k], param[k])\n",
    "        end\n",
    "        isa(state,Vector{Any}) || error(\"State should not be Boxed.\")\n",
    "        # The following is needed in case AutoGrad boxes state values during gradient calculation\n",
    "        for i = 1:length(state)\n",
    "            state[i] = AutoGrad.getval(state[i])\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# param[2k-1,2k]: weight and bias for the k'th lstm layer\n",
    "# param[end-2]: embedding matrix\n",
    "# param[end-1,end]: weight and bias for final prediction\n",
    "function initweights(atype, hidden, data, embed, winit)\n",
    "    dx, dy = size(data[1][1][1],2), size(data[1][1][2],2)\n",
    "    param = Array(Any, 2*length(hidden)+3)\n",
    "    input = embed\n",
    "    for k = 1:length(hidden)\n",
    "        param[2k-1] = winit*randn(input+hidden[k], 4*hidden[k])\n",
    "        param[2k]   = zeros(1, 4*hidden[k])\n",
    "        param[2k][1:hidden[k]] = 1 # forget gate bias\n",
    "        input = hidden[k]\n",
    "    end\n",
    "    param[end-2] = winit*randn(dx,embed)\n",
    "    param[end-1] = winit*randn(hidden[end],dy)\n",
    "    param[end] = zeros(1,dy)\n",
    "    return map(p->convert(atype,p), param)\n",
    "end\n",
    "\n",
    "# state[2k-1,2k]: hidden and cell for the k'th lstm layer\n",
    "function initstate(atype, hidden, batchsize)\n",
    "    state = Array(Any, 2*length(hidden))\n",
    "    for k = 1:length(hidden)\n",
    "        state[2k-1] = zeros(batchsize,hidden[k])\n",
    "        state[2k] = zeros(batchsize,hidden[k])\n",
    "    end\n",
    "    return map(s->convert(atype,s), state)\n",
    "end\n",
    "\n",
    "function lstm(weight,bias,hidden,cell,input)\n",
    "    gates   = hcat(input,hidden) * weight .+ bias\n",
    "    hsize   = size(hidden,2)\n",
    "    forget  = sigm(gates[:,1:hsize])\n",
    "    ingate  = sigm(gates[:,1+hsize:2hsize])\n",
    "    outgate = sigm(gates[:,1+2hsize:3hsize])\n",
    "    change  = tanh(gates[:,1+3hsize:end])\n",
    "    cell    = cell .* forget + ingate .* change\n",
    "    hidden  = outgate .* tanh(cell)\n",
    "    return (hidden,cell)\n",
    "end\n",
    "\n",
    "# s[2k-1,2k]: hidden and cell for the k'th lstm layer\n",
    "# w[2k-1,2k]: weight and bias for k'th lstm layer\n",
    "# w[end-2]: embedding matrix\n",
    "# w[end-1,end]: weight and bias for final prediction\n",
    "# state is modified in place\n",
    "function predict(w, s, x)\n",
    "    x = x * w[end-2]\n",
    "    for i = 1:2:length(s)\n",
    "        (s[i],s[i+1]) = lstm(w[i],w[i+1],s[i],s[i+1],x)\n",
    "        x = s[i]\n",
    "    end\n",
    "    return x * w[end-1] .+ w[end]\n",
    "end\n",
    "\n",
    "# sequence[t]: input token at time t\n",
    "# state is modified in place\n",
    "function loss(param,state,sequence,range=1:length(sequence)-1)\n",
    "    total = 0.0; count = 0\n",
    "    atype = typeof(AutoGrad.getval(param[1]))\n",
    "    for t in range\n",
    "        input = convert(atype,sequence[t][1])\n",
    "        ypred = predict(param,state,input)\n",
    "        ynorm = logp(ypred,2) # ypred .- log(sum(exp(ypred),2))\n",
    "        ygold = convert(atype,sequence[t][2])\n",
    "        total += sum(ygold .* ynorm)\n",
    "        count += size(ygold,1)\n",
    "    end\n",
    "    return -total / count\n",
    "end\n",
    "\n",
    "lossgradient = grad(loss)\n",
    "\n",
    "# To be able to load/save KnetArrays:\n",
    "if Pkg.installed(\"JLD\") != nothing\n",
    "    import JLD: writeas, readas\n",
    "    type KnetJLD; a::Array; end\n",
    "    writeas(c::KnetArray) = KnetJLD(Array(c))\n",
    "    readas(d::KnetJLD) = KnetArray(d.a)\n",
    "end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T19:26:20.173296",
     "start_time": "2016-11-02T11:26:22.016Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:epoch,0,:loss,1.741138853035964)\n",
      "  2.061764 seconds (120.88 k allocations: 650.245 MB, 31.63% gc time)\n",
      "  0.610034 seconds (36.66 k allocations: 270.742 MB)\n",
      "(:epoch,1,:loss,10.627558485254065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: New learning rate: 0.9\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.236612 seconds (50.21 k allocations: 647.416 MB, 11.54% gc time)\n",
      "  0.366460 seconds (13.94 k allocations: 269.743 MB)\n",
      "(:epoch,2,:loss,1.6119618957692927)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: Saving best model to /tmp/CharLM-best.jld\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.461812 seconds (50.21 k allocations: 647.416 MB, 31.73% gc time)\n",
      "  0.513725 seconds (13.94 k allocations: 269.743 MB)\n",
      "(:epoch,3,:loss,8.046358851643351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: New learning rate: 0.81\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "x = rand(1000,10000)\n",
    "y = rand(2,10000)\n",
    "model = RNN.initialize(x,y, o)\n",
    "RNN.train!(model, data, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T19:55:49.917417",
     "start_time": "2016-11-02T11:55:59.008Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "text = readstring(\"/home/rluser/.julia/v0.5/Knet/data/101.txt\")\n",
    "vocab = Dict{Char,Int}()\n",
    "for t in text, c in t; get!(vocab, c, 1+length(vocab)); end\n",
    "RNN.lab\n",
    "\n",
    "# index_to_char = Array(Char, length(vocab))\n",
    "#     for (k,v) in vocab; index_to_char[v] = k; end\n",
    "#     input = oftype(param[1], zeros(1,length(vocab)))\n",
    "#     index = 1\n",
    "#     for t in 1:nchar\n",
    "#         ypred = predict(param,state,input)\n",
    "#         input[index] = 0\n",
    "#         index = sample(exp(logp(ypred)))\n",
    "#         print(index_to_char[index])\n",
    "#         input[index] = 1\n",
    "#     end\n",
    "#     println()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
